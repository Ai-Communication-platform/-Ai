{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybDReD8D3r-Y",
        "outputId": "793518f8-ca70-4993-889c-115c16f369d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **💬개요**\n",
        "---\n",
        "\n",
        "- LDA (Latent Dirichlet Allocation)는 토픽 모델링 기법 중 하나로, 주어진 문서들에서 주제를 찾아내는 데 사용되는 알고리즘임.\n",
        "- LDA 주제 분석을 진행하는 과정\n",
        "  1. 데이터 전처리: 텍스트 데이터를 분석하기\n",
        "  적합한 형태로 변환합니다. 이 과정에서 불용어 제거, 소문자 변환, 토큰화 등의 작업을 수행\n",
        "    - 불용어 제거: 텍스트에서 의미 없는 단어나 빈번하게 등장하는 단어를 제거한다.\n",
        "    - 토큰화: 문서를 개별 단어로 분리한다.\n",
        "    - 어간 추출 및 표제어 추출: 단어의 기본형을 추출하여 문서 내 단어의 다양성을 줄인다.\n",
        "    - 소문자 변환: 단어의 대소문자를 통일하여 분석의 정확성을 높입니다.\n",
        "  2. 단어-문서 매트릭스 생성: 전처리된 텍스트 데이터를 바탕으로, 각 문서와 단어 간의 빈도를 나타내는 매트릭스를 생성\n",
        "    - 이 매드릭스는 문서별로 단어의 등장 빈도를 나타내며, LDA 알고리즘에 입력으로 사용된다.\n",
        "  3. LDA 모델 학습: LDA 알고리즘을 적용하여 주제 분석을 진행.\n",
        "    - 이때, 토픽 수를 미리 지정해야 한다. 토픽 수는 하이퍼파라미터임.\n",
        "    - LDA 알고리즘은 각 문서의 토픽 분포와 각 토픽의 단어 분포를 추정한다.\n",
        "    - LDA는 다음과 같은 가정에 기반한다.  \n",
        "      (1) 각 문서는 여러 개의 토픽으로 구성되어 있다.  \n",
        "      (2) 각 토픽은 확률 분포에 따라 단어를 생성한다.\n",
        "    - LDA는 이러한 가정을 바탕으로 주어진 문서에서 **토픽 분포**와 **단어 분포**를 추정하는 과정을 반복하며 최적의 값을 찾아낸다.\n",
        "  4. 결과 해석:\n",
        "    - 학습된 LDA 모델을 사용하여 각 문서의 토픽 분포와 각 토픽의 주요 단어들을 확인한다.\n",
        "    - 각 문서의 토픽 분포를 바탕으로 문서들 간의 유사성을 파악할 수 있다.\n",
        "    - 각 토픽의 주요 단어들을 통해 해당 토픽이 어떤 주제를 나타내는지 해석할 수 있다."
      ],
      "metadata": {
        "id": "6OxlqTLMvG1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **👁️‍🗨️ Expample**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "예를 들어, 3개의 뉴스 기사를 분석한다고 가정해보자. 각 기사는 다음과 같은 내용을 담고 있다.\n",
        "\n",
        "- 기사 1: 스마트폰 관련 기술 발전과 최신 스마트폰 소식  \n",
        "- 기사 2: 축구 경기 결과와 축구 선수들의 활약 소식  \n",
        "- 기사 3: 최근 인공지능 기술의 발전과 활용 사례  \n",
        "\n",
        "## **1. 데이터 전처리**\n",
        "  - 불용어 제거: '그리고', '하지만' 같은 의미 없는 단어들을 제거한다.\n",
        "  - 토큰화: 각 기사를 개별 단어로 분리한다.\n",
        "  - 어간 추출 및 표제어 추출: '발전하다', '발전한' 등의 단어를 '발전'으로 통일한다.\n",
        "  - 소문자 변환: 'Smartphone', 'smartphone'과 같이 대소문자가 다른 단어를 통일한다.\n",
        "\n",
        "## **2. 단어-문서 매트릭스 생성**\n",
        "  - 전처리된 텍스트 데이터를 바탕으로 단어-문서 매트릭스를 생성한다.\n",
        "  - 예를 들어, 기사 1에서 '스마트폰'이 5번, '기술'이 3번 등장한다면, 매트릭스의 해당 위치에 빈도를 기록한다.\n",
        "  - 각 기사에서 추출한 단어들을 아래와 같다고 가정하자.\n",
        "    - 기사 1: ['스마트폰', '기술', '발전', '최신', '소식']  \n",
        "    - 기사 2: ['축구', '경기', '결과', '선수', '활약', '소식']  \n",
        "    - 기사 3: ['최근', '인공지능', '기술', '발전', '활용', '사례']  \n",
        "  - 이를 바탕으로 단어-문서 매트릭스를 생성 예시는 아래와 같다.  \n",
        "  \n",
        "|      | 기사 1 | 기사 2 | 기사 3 |\n",
        "|------|--------|--------|--------|\n",
        "| 스마트폰 |   5   |   0   |   0   |\n",
        "| 기술 |   3   |   0   |   4   |\n",
        "| 발전 |   2   |   0   |   3   |\n",
        "| 최신 |   2   |   0   |   0   |\n",
        "| 소식 |   1   |   2   |   0   |\n",
        "| 축구 |   0   |   4   |   0   |\n",
        "| 경기 |   0   |   3   |   0   |\n",
        "| 결과 |   0   |   2   |   0   |\n",
        "| 선수 |   0   |   2   |   0   |\n",
        "| 활약 |   0   |   2   |   0   |\n",
        "| 최근 |   0   |   0   |   2   |\n",
        "| 인공지능 |   0   |   0   |   3   |\n",
        "| 활용 |   0   |   0   |   2   |\n",
        "| 사례 |   0   |   0   |   1   |\n",
        "\n",
        "- 이렇게 생성된 단어-문서 매트릭스는 LDA 모델 학습의 입력으로 사용된다.\n",
        "## **3. LDA 모델 학습**\n",
        "  - 미리 지정한 토픽 수에 따라 LDA 알고리즘을 학습시킵니다. 여기서는 3개의 토픽을 가정해보자.\n",
        "  - LDA는 각 기사에 대해 토픽 분포를 추정하고, 각 토픽에 대해 단어 분포를 추정한다.\n",
        "## **4. 결과 해석**\n",
        "  - 학습된 LDA 모델을 사용하여 각 기사의 토픽 분포와 각 토픽의 주요 단어들을 확인한다.\n",
        "  - 예를 들어, 토픽 1의 주요 단어로 '스마트폰', '기술'이 확인되면 이 토픽은 스마트폰 기술과 관련된 주제로 해석할 수 있다.\n",
        "  - 토픽 2의 경우 '축구', '경기', '선수'와 같은 단어가 주요 단어로 확인되면, 축구와 관련된 주제로 해석할 수 있다.\n",
        "  - 토픽 3의 경우 '인공지능', '기술', '활용' 등의 단어가 주요 단어로 확인되면, 인공지능 기술과 관련된 주제로 해석할 수 있다.\n",
        "  - 각 기사의 토픽 분포를 통해 기사들이 어떤 주제와 관련되어 있는지 파악할 수 있다. 예를 들어, 기사 1은 토픽 1에 가장 높은 확률을 가지면 스마트폰 기술과 관련된 기사로 분류할 수 있다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gt9_j8S20Eaw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5zOjEnYu-td"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# 전처리된 텍스트 데이터 (예시)\n",
        "texts = [['고양이', '애교', '귀여움'],\n",
        "         ['개', '충성', '친구'],\n",
        "         ['고양이', '잠', '많음'],\n",
        "         ...]\n",
        "\n",
        "# 단어-문서 매트릭스 생성\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# LDA 모델 학습\n",
        "lda = LdaModel(corpus, num_topics=3, id2word=dictionary, passes=20)\n",
        "\n",
        "# 결과 해석\n",
        "topics = lda.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA를 사용한 주제 분석은 다양한 분야에서 활용될 수 있으며, 이를 통해 문서들 간의 유사성을 파악하거나 주요 키워드를 추출하는 등의 작업을 수행할 수 있습니다."
      ],
      "metadata": {
        "id": "-dxdwWB4vGaB"
      }
    }
  ]
}